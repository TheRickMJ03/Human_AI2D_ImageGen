# Human_AI2D_ImageGen  

**Generate, iterate, and transform text into images ‚Äî and images into 3D models ‚Äî with multi-provider AI.**  

---

## ‚ú® Overview  

**Human_AI2D_ImageGen** is a loccally hosted, full-stack web application for **AI-powered image generation, editing, segmentation, and 3D reconstruction**.  
## Demo

![demo_2](https://github.com/user-attachments/assets/bf8264d8-bb93-4596-9ecc-17790f2eb6c6)



It integrates **external AI providers** with **VM-hosted machine learning models** into one workflow:  

- üåê **External AI Providers (Cloud APIs)**  
  - **OpenAI** ‚Üí DALL¬∑E, GPT-Image  
  - **Google** ‚Üí Imagen, Gemini 2.0 Flash  
  - **Hugging Face** ‚Üí FLUX.1-schnell, SDXL  

- üíª **Local ML Models (VM)**  
  - **[SAM2 (Segment Anything Model 2)](https://github.com/facebookresearch/sam2)** ‚Üí segmentation (`SAM_server.py`)  
  - **[LGM (Large Multi-View Gaussian Model)](https://github.com/3DTopia/LGM)** ‚Üí 3D reconstruction (`infer_3sides.py`)  

**Key Features**  
- üîÑ Real-time WebSocket updates during generation  
- üñºÔ∏è Persistent gallery with prompts, descriptions, and thumbnails  
- ‚úçÔ∏è Iteration with Gemini for refinement & extension  
- ‚úÇÔ∏è SAM2-powered segmentation and mask extraction  
- üß© Full **2D ‚Üí 3D pipeline** using LGM (`.ply` export)  
- üíæ Local storage with timestamped filenames  

---

## üõ†Ô∏è Built With  

- [React](https://react.dev/) ‚Äî Frontend  
- [Flask](https://flask.palletsprojects.com/) ‚Äî Backend API  
- [Socket.IO](https://socket.io/) ‚Äî Real-time communication  
- [Hugging Face Hub](https://huggingface.co/) ‚Äî SDXL & FLUX inference  
- [OpenAI API](https://platform.openai.com/) ‚Äî DALL¬∑E & GPT-Image  
- [Google Vertex AI](https://cloud.google.com/vertex-ai) ‚Äî Imagen & Gemini  
- [Pillow (PIL)](https://python-pillow.org/) ‚Äî Image preprocessing  
- [SAM2](https://github.com/facebookresearch/sam2) ‚Äî Segmentation (VM)  
- [LGM](https://github.com/3DTopia/LGM) ‚Äî 3D reconstruction (VM)  

---

## üìÇ Project Structure  

```plaintext
Human_AI2D_ImageGen/
‚îÇ
‚îú‚îÄ‚îÄ .vscode/                 # VSCode project settings
‚îú‚îÄ‚îÄ node_modules/            # React dependencies
‚îú‚îÄ‚îÄ src/                     # React frontend app
‚îÇ   ‚îú‚îÄ‚îÄ assets/              # Static images, CSS
‚îÇ   ‚îú‚îÄ‚îÄ components/          # Modular UI components
‚îÇ   ‚îú‚îÄ‚îÄ lib/                 # Utility functions
‚îÇ   ‚îú‚îÄ‚îÄ App.js               # Main React component
‚îÇ   ‚îî‚îÄ‚îÄ index.js             # Entry point
‚îÇ
‚îú‚îÄ‚îÄ server/                  # Flask backend + VM services
‚îÇ   ‚îú‚îÄ‚îÄ 3d_models/           # Output `.ply` meshes from LGM
‚îÇ   ‚îú‚îÄ‚îÄ generated_images/    # Saved/generated images
‚îÇ   ‚îú‚îÄ‚îÄ segmented_images/    # Image masks/outputs from SAM2
‚îÇ   ‚îú‚îÄ‚îÄ VM_Server/           # Local ML services (SAM2 & LGM)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SAM_server.py    # Segmentation (SAM2)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ infer_3sides.py  # 3D reconstruction (LGM)
‚îÇ   ‚îú‚îÄ‚îÄ image_generator.py   # Main Flask app (API routes)
‚îÇ   ‚îú‚îÄ‚îÄ sa_key.json          # Google service account key
‚îÇ   ‚îî‚îÄ‚îÄ .env                 # Runtime environment variables
‚îÇ
‚îú‚îÄ‚îÄ .env                     # Global environment config (if needed)
‚îú‚îÄ‚îÄ .env.example             # Template for setting env variables
‚îú‚îÄ‚îÄ .gitignore               # Git ignore rules
‚îú‚îÄ‚îÄ package.json             # React frontend dependencies
‚îú‚îÄ‚îÄ package-lock.json        # Exact dependency tree
‚îú‚îÄ‚îÄ README.md                # Documentation

```

---

## üöÄ Running the System  

### 1Ô∏è‚É£ Backend (Flask)  
```bash
cd server
python3 -m venv venv
source venv/bin/activate      # Windows: venv\Scripts\activate
pip install -r requirements.txt
python image_generator.py     # runs on http://0.0.0.0:5000
```

### 2Ô∏è‚É£ Frontend (React)  
```bash
cd public
npm install
npm start                     # runs on http://localhost:3000
```

### 3Ô∏è‚É£ VM Services  

#### üñºÔ∏è Segmentation (SAM2)  
**Prerequisites**  
- Python 3.10+ with PyTorch  
- SAM2 dependencies installed  
- Model weights: `sam_vit_h_4b8939.pth`  

**Startup**  
```bash
cd ~/SAM/sam2
source ../env/bin/activate
python SAM_server.py
```

#### üß© 3D Reconstruction (LGM)  
**Prerequisites**  
- CUDA-enabled GPU  
- Python 3.9+ with PyTorch (CUDA)  
- LGM dependencies installed  

**Startup**  
```bash
cd ~/LMGM/LGM
source ../LGMenv_2/bin/activate
python infer_3sides.py big --resume pretrained/model_fp16_fixrot.safetensors --workspace output_test
```

---

## üåê AI Providers vs Local Models  

- **Cloud Providers (API keys required)**  
  - OpenAI ‚Üí `/save_openai_image`  
  - Hugging Face ‚Üí `/generate`  
  - Google (Imagen, Gemini) ‚Üí `/imagen`, `/gemini`  

- **Local VM Models (Flask ‚Üî VM via HTTP)**  
  - SAM2 (Segmentation) ‚Üí `/segment_with_sam`  
  - LGM (3D Reconstruction) ‚Üí `/generate_3d_direct`  

---

## üñ•Ô∏è System Workflow  

```mermaid
sequenceDiagram
  participant User as User (Frontend)
  participant Flask as Flask Server (Local API)
  participant SAM as SAM_server (Segmentation, port 5000)
  participant Infer as infer_3sides (3D Backend, port 5001)
  participant Gemini as Google Gemini API
  participant Imagen as Google Imagen API
  participant HF as Hugging Face API
  participant OpenAI as OpenAI Images

  User ->> Flask: POST /segment_with_sam
  Flask ->> SAM: POST /segment
  SAM -->> Flask: Masks, bbox, visualization
  Flask -->> User: JSON response

  User ->> Flask: POST /generate_3d_direct
  Flask ->> Infer: POST /process
  Infer -->> Flask: PLY data
  Flask -->> User: JSON + metadata

  User ->> Flask: POST /gemini
  Flask ->> Gemini: generate_content
  Gemini -->> Flask: Image response
  Flask -->> User: Emits new_image event

  User ->> Flask: POST /generate
  Flask ->> HF: text_to_image
  HF -->> Flask: Image bytes
  Flask -->> User: Emits new_image

  User ->> Flask: POST /imagen
  Flask ->> Imagen: predict
  Imagen -->> Flask: Image bytes
  Flask -->> User: Emits new_image

  User ->> Flask: POST /save_openai_image
  Flask ->> OpenAI: GET image
  OpenAI -->> Flask: Image bytes
  Flask -->> User: Emits new_image

  User ->> Flask: GET /Thumbnails
  Flask -->> User: JSON list of saved images
```

---

## ‚öôÔ∏è Environment Setup  

Create `.env` inside `server/`:  

```ini
HF_API_TOKEN=your_huggingface_token_here
GOOGLE_CLOUD_PROJECT=your_gcp_project_id
GOOGLE_APPLICATION_CREDENTIALS=/path/to/sa_key.json
```

- Place `sa_key.json` (Google service account key) in `server/`.  

---

## üé® Usage  

1. Start **Flask backend** + **React frontend**  
2. Launch **SAM2** + **LGM** inside the VM  
3. Open the UI ‚Üí [http://localhost:3000](http://localhost:3000)  
4. Select a provider (**OpenAI**, **Hugging Face**, **Google**)  
5. Enter prompt ‚Üí generate images  
6. View saved generations in **Gallery**  
7. Use **Gemini iteration** or **SAM2 segmentation** for refinements  
8. Convert regions into **3D models (`.ply`)** via **LGM**  

---

## üì° API Endpoints  

### Hugging Face  
```http
POST /generate
{
  "prompt": "A medieval city at sunset",
  "model": "black-forest-labs/FLUX.1-schnell",
  "provider": "together"
}
```

### Google Imagen  
```http
POST /imagen
{
  "prompt": "A futuristic robot portrait",
  "model": "imagen-4.0-generate-preview-06-06",
  "size": "1024x1024"
}
```

### Google Gemini (iteration)  
```http
POST /gemini
{
  "prompt": "Add a golden crown",
  "image_filename": "previous_prompt__timestamp.png",
  "model": "gemini-2.0-flash-preview-image-generation"
}
```

### Segmentation (SAM2)  
```http
POST /segment_with_sam
{
  "image_url": "/generated_images/example.png",
  "input_points": [[100, 150]],
  "input_labels": [1]
}
```

### 2D ‚Üí 3D Conversion (LGM)  
```http
POST /generate_3d_direct
{
  "image_url": "/generated_images/example.png",
  "mask_data": "data:image/png;base64,...."
}
```

---

## üìå Notes  

- Requires **GPU-accelerated VM** for SAM2 + LGM.  
- Cloud APIs (OpenAI, Hugging Face, Google) need active tokens/credentials.  
- All generated assets are **timestamped** for reproducibility.  

### üöß Work in Progress  
- **Reset feature:** A button to re-align the 3D object perfectly over the 2D image (including position and rotation).  
- **Improvement 1:** Adjusting the size and initial placement of the `.ply` file so that the 3D object (e.g., hat) matches the scale and position of the corresponding 2D object.  
